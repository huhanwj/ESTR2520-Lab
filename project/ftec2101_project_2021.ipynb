{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Project \n",
    "\n",
    "The aim of this project is to solve various forms of the portfolio optimization problem through Julia/computer software. This program template will provide hints/template code for you to focus on the optimization formulation part.\n",
    "\n",
    "As usual, we first need to load a few packages in Julia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I - Compulsory Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JuMP related packages and several solvers\n",
    "# ECOS - for solving SOCP problems\n",
    "# Juniper & Ipopt - for solving MI-NLP problems\n",
    "using JuMP, Juniper, ECOS, Ipopt\n",
    "# Load the data/file processing related packages\n",
    "using CSV, Glob, DataFrames, Statistics\n",
    "# Load the Plot package for illustrating the solution\n",
    "using Plots\n",
    "# Load the custom functions for benchmarking  \n",
    "include(\"./reusablefunc.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing\n",
    "The first step is to load the raw data into the memory. The following codes are provided for you to help you get started. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change \"subgroup1\" to other names according to the subgroup you are assigned.\n",
    "path_subgroup = \"./ftec_project_subgroup2/\" \n",
    "files = glob( \"*_train.csv\", path_subgroup );\n",
    "dfs = DataFrame.( CSV.File.( files ) );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 800; n = length(dfs);\n",
    "stocks_retur = zeros(T,n);\n",
    "for i = 1:n\n",
    "    # compute the realized return R_i(t)\n",
    "    stocks_retur[:,i] = (dfs[i].close-dfs[i].open) ./ dfs[i].open;\n",
    "end\n",
    "names_stocks = [ dfs[i].Name[1] for i in 1:n ];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Warm-up Exercise\n",
    "\n",
    "For part (a) of this task, you have to plot the return of 3-4 stocks over time. An example is provided for you as follows. Use \"Insert\" -> \"Insert Cell Below/After\" if you want to keep the plots together in one place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_id = 1; # You may change this stock_id to different numbers from 1 to 20\n",
    "plot( dfs[stock_id].date, stocks_retur[:,stock_id] , label = dfs[stock_id].Name[1], title = dfs[stock_id].Name[1]*\"'s return over time\" )\n",
    "savefig(\"stock1.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_id = 8; # You may change this stock_id to different numbers from 1 to 20\n",
    "plot( dfs[stock_id].date, stocks_retur[:,stock_id] , label = dfs[stock_id].Name[1], title = dfs[stock_id].Name[1]*\"'s return over time\" )\n",
    "savefig(\"stock2.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_id = 15; # You may change this stock_id to different numbers from 1 to 20\n",
    "plot( dfs[stock_id].date, stocks_retur[:,stock_id] , label = dfs[stock_id].Name[1], title = dfs[stock_id].Name[1]*\"'s return over time\" )\n",
    "savefig(\"stock3.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_id = 20; # You may change this stock_id to different numbers from 1 to 20\n",
    "plot( dfs[stock_id].date, stocks_retur[:,stock_id] , label = dfs[stock_id].Name[1], title = dfs[stock_id].Name[1]*\"'s return over time\" )\n",
    "savefig(\"stock4.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For part (b) of this task, we need to estimate the expected return $\\hat{r}_i$ and covariance $\\hat\\rho_{ij}$. Notice that these terms are given by (1.6) in the project specification. For your convenience, they have been calculated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate r_i and Sigma\n",
    "bar_R = [ mean( stocks_retur[:,i] ) for i in 1:length(dfs) ];\n",
    "Sigma = [ mean( (stocks_retur[:,i].-bar_R[i]).*(stocks_retur[:,j].-bar_R[j]) ) for i=1:n, j=1:n ]; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where \"bar_R\" is a $20$-dimensional vector containing the expected return $\\hat{r}$ for the stocks; and \"Sigma\" is the $20 \\times 20$ matrix of the covariance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Closed Form Solution to (1.1)\n",
    "\n",
    "This task computes the optimal portfolio using the closed form solution derived in Task 1. Here are a few hints of useful syntax in computing the optimal solution:\n",
    "\n",
    "- To compute the inverse of a square matrix, e.g., \"$\\texttt{Sigma}$\", it can be done by \n",
    "$$\\texttt{Sigma^-1}$$\n",
    "- To create a (column) vector of all ones of $n$-dimensional. you may use \n",
    "$$\\texttt{ones(n)}.$$ \n",
    "- In your closed form solution, you may need encounter something such as ${\\bf 1}^\\top {S} {b}$ for some $n \\times n$ square matrix ${S}$, and $n$-dimensional vector ${b}$. The above expression can be computed in Julia as\n",
    "$$\\texttt{ones(n)'*S*b}$$\n",
    "where $\\texttt{ones(n)'}$ has denoted the transpose of the vector $\\texttt{ones(n)}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "B = 20;\n",
    "B1=30;\n",
    "B2=40;\n",
    "one_vec = ones(20);\n",
    "Rd = 1.01 * sum(bar_R);\n",
    "Rd1 = 1.1*sum(bar_R);\n",
    "Rd2 = 1.5*sum(bar_R);\n",
    "r0 = bar_R'*Sigma^-1*bar_R;\n",
    "r1 = one_vec'*Sigma^-1*bar_R;\n",
    "r2 = one_vec'*Sigma^-1*one_vec;\n",
    "portfolio_opt = Sigma^-1 *((r0*B-r1*Rd)*one_vec+(r2*Rd-r1*B)*bar_R)/(r0*r2-r1^2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_opt1 = Sigma^-1 *((r0*B1-r1*Rd)*one_vec+(r2*Rd-r1*B1)*bar_R)/(r0*r2-r1^2);\n",
    "portfolio_opt2 = Sigma^-1 *((r0*B2-r1*Rd)*one_vec+(r2*Rd-r1*B2)*bar_R)/(r0*r2-r1^2);\n",
    "portfolio_opt3 = Sigma^-1 *((r0*B-r1*Rd1)*one_vec+(r2*Rd1-r1*B)*bar_R)/(r0*r2-r1^2);\n",
    "portfolio_opt4 = Sigma^-1 *((r0*B-r1*Rd2)*one_vec+(r2*Rd2-r1*B)*bar_R)/(r0*r2-r1^2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that $\\texttt{portfolio_opt}$ has been created as a 20-dimensional vector of the optimal portfolio. The following helper code should plot the comparison of the portfolio for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot( names_stocks, portfolio_opt, labels = \"portfolio\", xticks = :all )\n",
    "# you may adjust the scale factor \"1000\" to scale up/down the expected return to make it comparable with \n",
    "# the value of the portfolio (*for improved visualization only*).\n",
    "plot!( names_stocks, 3000*bar_R , labels = \"(scaled) expected return\") \n",
    "plot!( names_stocks, 3000*[Sigma[i,i] for i in 1:n], labels = \"(scaled) variance\" )\n",
    "savefig(\"5-normal.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot( names_stocks, portfolio_opt, labels = \"portfolio-B=20\", xticks = :all )\n",
    "plot!(names_stocks, portfolio_opt1, labels = \"portfolio-B=30\", xticks = :all )\n",
    "plot!(names_stocks, portfolio_opt2, labels = \"portfolio-B=40\", xticks = :all )\n",
    "# you may adjust the scale factor \"1000\" to scale up/down the expected return to make it comparable with \n",
    "# the value of the portfolio (*for improved visualization only*).\n",
    "plot!( names_stocks, 3000*bar_R , labels = \"(scaled) expected return\") \n",
    "plot!( names_stocks, 3000*[Sigma[i,i] for i in 1:n], labels = \"(scaled) variance\" )\n",
    "savefig(\"5-exp-B.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot( names_stocks, portfolio_opt, labels = \"portfolio-Rd=1.01\", xticks = :all )\n",
    "plot!(names_stocks, portfolio_opt3, labels = \"portfolio-Rd=1.1\", xticks = :all )\n",
    "plot!(names_stocks, portfolio_opt4, labels = \"portfolio-Rd=1.5\", xticks = :all )\n",
    "# you may adjust the scale factor \"1000\" to scale up/down the expected return to make it comparable with \n",
    "# the value of the portfolio (*for improved visualization only*).\n",
    "plot!( names_stocks, 3000*bar_R , labels = \"(scaled) expected return\") \n",
    "plot!( names_stocks, 3000*[Sigma[i,i] for i in 1:n], labels = \"(scaled) variance\" )\n",
    "savefig(\"5-exp-Rd.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6 (a): Mixed Integer Programming Solution\n",
    "\n",
    "For this task, we shall implement the MI-NLP problem. As usual, we have to define the optimization object and specify a few parameters, as follows. The solver we are going to apply is \"Juniper\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following code specifies the constants as described in the problem\n",
    "M = 20; B = 20; c = 2; w = 1*ones(n); Rd = 1.01*sum( w.*bar_R ); \n",
    "\n",
    "# the following code setup the JuMP model with the right solver\n",
    "nl_solver = optimizer_with_attributes(Ipopt.Optimizer, \"print_level\"=>0)\n",
    "optimizer = Juniper.Optimizer\n",
    "model = Model(optimizer_with_attributes(optimizer, \"nl_solver\"=>nl_solver, \"atol\"=>1e-10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can program the MI-NLP problem in the following cell and solve it. Here are a few hints that maybe useful.\n",
    "\n",
    "- To be compatible with the helper codes in the latter section, please call the decision variable for the portfolio by \"x_mip\". \n",
    "- You may use for-loop to specify a large number of constraints. \n",
    "- To model constraint given in the form of \n",
    "$$ \\sum_{i=1}^n x_i y_i \\geq r $$\n",
    "withe the $n$-dimensional vectors $x$, $y$. You may do so by\n",
    "\n",
    "$$ \\texttt{@constraint(model, sum( x .* y ) >= r)} $$\n",
    "\n",
    "where $\\texttt{.*}$ denotes an \"element-wise\" product \n",
    "- To minimize quadratic function of the form\n",
    "$$ f(x) = x^\\top \\Sigma x $$\n",
    "\n",
    "we first notice that \n",
    "\n",
    "$$ f(x) = ( \\Sigma^{1/2} x )^\\top ( \\Sigma^{1/2} x ) $$\n",
    "\n",
    "and the above can be modeled in JuMP by\n",
    "\n",
    "$$ \\texttt{@variable( model, y[1:n] )}$$\n",
    "$$ \\texttt{@constraint( model, y .== sqrt(Sigma)*x );}$$ \n",
    "$$ \\texttt{@NLobjective( model, Min, sum(y[i]^2 for i in 1:n) )} $$\n",
    "\n",
    "Notice that we shall use \"$\\texttt{NLObjective}$ to specify that the objective function is nonlinear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atol              : 1.0e-10\n",
      "nl_solver         : MathOptInterface.OptimizerWithAttributes(Ipopt.Optimizer, Pair{MathOptInterface.AbstractOptimizerAttribute,Any}[RawParameter(\"print_level\")=>0])\n",
      "feasibility_pump  : false\n",
      "log_levels        : Symbol[:Options, :Table, :Info]\n",
      "\n",
      "#Variables: 60\n",
      "#IntBinVar: 20\n",
      "#Constraints: 82\n",
      "#Linear Constraints: 82\n",
      "#Quadratic Constraints: 0\n",
      "#NonLinear Constraints: 0\n",
      "Obj Sense: Min\n",
      "\n",
      "Start values are not feasible.\n",
      "Status of relaxation: LOCALLY_SOLVED\n",
      "Time for relaxation: 0.06200003623962402\n",
      "Relaxation Obj: 0.004248858348537353\n",
      "\n",
      " ONodes   CLevel          Incumbent                   BestBound            Gap    Time   Restarts  GainGap  \n",
      "============================================================================================================\n",
      "    2       2                 -                          0.0                -     0.5       0         -     \n",
      "    3       3                 -                          0.0                -     0.5       -       77.5%   \n",
      "    4       4                 -                          0.0                -     0.5       -       78.3%   \n",
      "    5       5                 -                          0.0                -     0.5       -       79.2%   \n",
      "    6       6                 -                          0.0                -     0.5       -       79.6%   \n",
      "    7       7                 -                          0.0                -     0.6       -       81.4%   \n",
      "    8       8                 -                          0.0                -     0.6       -       82.7%   \n",
      "    9       9                 -                          0.0                -     0.6       -       84.2%   \n",
      "   10       10                -                          0.0                -     0.6       -       86.0%   \n",
      "   11       11                -                          0.0                -     0.7       -       89.0%   \n",
      "   12       12                -                          0.0                -     0.7       -       90.4%   \n",
      "   13       13                -                          0.0                -     0.7       -       92.3%   \n",
      "   14       14                -                          0.0                -     0.8       -       94.8%   \n",
      "   15       15                -                          0.0                -     0.8       -       97.2%   \n",
      "   16       16                -                          0.0                -     0.8       -       99.6%   \n",
      "   17       17                -                          0.0                -     0.8       -       100.0%  \n",
      "   18       18                -                          0.0                -     0.9       -       100.0%  \n",
      "   19       16                -                          0.0                -     0.9       -       478.9%  \n",
      "   20       17                -                          0.0                -     0.9       -       83.3%   \n",
      "   21       18                -                          0.0                -     1.0       -       96.3%   \n",
      "   22       19                -                          0.0                -     1.0       -       100.0%  \n",
      "   22       20                -                          0.0                -     1.0       -       98.5%   \n",
      "   23       17                -                          0.0                -     1.1       -       93.8%   \n",
      "   24       18                -                          0.0                -     1.1       -       69.9%   \n",
      "   25       15                -                          0.0                -     1.2       -       57.1%   \n",
      "   26       16                -                          0.0                -     1.2       -       434.6%  \n",
      "   27       17                -                          0.0                -     1.2       -       94.1%   \n",
      "    2       21             0.00459                     0.00458            0.19%   1.3       -       97.0%   \n",
      "    3       14             0.004591                    0.004587           0.07%   1.3       -       268.4%  \n",
      "    3       15             0.004591                    0.004587           0.07%   1.3       -       286.1%  \n",
      "    3       16             0.004591                    0.004587           0.07%   1.4       -       94.2%   \n",
      "    2       17             0.004591                    0.004587           0.07%   1.4       -       99.1%   \n",
      "    2       15             0.004591                    0.004588           0.06%   1.4       -       64.8%   \n",
      "    2       16             0.004591                    0.004588           0.06%   1.5       -       92.5%   \n",
      "    2       17             0.004591                    0.004588           0.06%   1.5       -       96.2%   \n",
      "    1       18             0.004591                    0.004588           0.06%   1.5       -       98.9%   \n",
      "\n",
      "#branches: 36\n",
      "Obj: 0.004590697465651076\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "n = 20;\n",
    "@variable(model, k[1:n]);\n",
    "@variable(model, y[1:n], Bin);\n",
    "@variable(model, x_mip[1:n]);\n",
    "@constraint(model, k .== sqrt(Sigma)*(x_mip+w));\n",
    "@constraint(model, sum((x_mip+w) .* bar_R) >= Rd);\n",
    "@constraint(model, sum(x_mip+y.*c)<=B);\n",
    "@constraint(model, x_mip .>= -M.*y);\n",
    "@constraint(model, x_mip .<= M.*y);\n",
    "@constraint(model, x_mip .>= -w);\n",
    "@NLobjective(model, Min, sum(k[i]^2 for i in 1:n));\n",
    "optimize!(model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6(b): SOCP Solution\n",
    "\n",
    "For this task, we shall implement the SOCP program formulated in Task 3. As usual, we have to define the optimization object and specify a few parameters, as follows. The solver we are going to apply is \"ECOS\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the problem parameters\n",
    "M = 20; B = 20; a = 2; w = ones(n); Rd = 1.01*sum( w.*bar_R ); \n",
    "# specify the JuMP model with ECOS as the optimizer\n",
    "m_socp = Model( ECOS.Optimizer );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may program the SOCP problem into JuMP as follows. Again, for convenience, you may name the decision variable of the portfolio as \"x_socp\". \n",
    "\n",
    "Further, wou may find that some constraints are similar to the MI-NLP from the previous task. However, when you \"copy-and-paste\" those code, don't forget to change the model name and the variable name. Here are some hints on modeling the second order cone constraints:\n",
    "\n",
    "- To model a SOC constraint given in the form\n",
    "\n",
    "$$ \\| Ax + d \\| \\leq c^\\top x + d, $$\n",
    "\n",
    "you can use\n",
    "\n",
    "$$ \\texttt{ @constraint( m_socp, [c'*x + d; A*x + d] in SecondOrderCone() ) } $$\n",
    "\n",
    "Essentially, \"$\\texttt{[c'*x + d; A*x + d]}$\" defines a vector whose first element describes the RHS of the SOC constraint, the the remaining elements describe the vector found inside the norm of the SOC constraint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ECOS 2.0.5 - (C) embotech GmbH, Zurich Switzerland, 2012-15. Web: www.embotech.com/ECOS\n",
      "\n",
      "It     pcost       dcost      gap   pres   dres    k/t    mu     step   sigma     IR    |   BT\n",
      " 0  +0.000e+00  -8.984e+02  +1e+03  8e-02  6e-01  1e+00  2e+01    ---    ---    1  1  - |  -  - \n",
      " 1  +1.005e+00  -4.956e+02  +6e+02  4e-02  5e-01  3e+00  1e+01  0.5795  3e-01   1  1  1 |  0  0\n",
      " 2  +7.074e-01  -1.868e+02  +2e+02  2e-02  2e-01  1e+00  4e+00  0.6350  5e-02   1  1  1 |  0  0\n",
      " 3  +1.114e+00  -1.236e+02  +2e+02  1e-02  2e-02  2e+00  2e+00  0.8912  6e-01   1  2  2 |  0  0\n",
      " 4  +1.214e-01  -1.409e+01  +2e+01  1e-03  5e-03  2e-01  3e-01  0.9091  4e-02   2  2  2 |  0  0\n",
      " 5  +1.102e-01  -4.652e-01  +8e-01  5e-05  1e-03  9e-03  1e-02  0.9890  3e-02   2  2  2 |  0  0\n",
      " 6  +8.429e-02  -2.818e-02  +2e-01  1e-05  2e-04  2e-03  3e-03  0.8194  2e-02   1  1  1 |  0  0\n",
      " 7  +8.578e-02  -1.586e-02  +1e-01  9e-06  2e-04  2e-03  2e-03  0.2615  6e-01   1  1  1 |  0  0\n",
      " 8  +7.437e-02  +3.386e-02  +6e-02  4e-06  8e-05  6e-04  9e-04  0.7519  2e-01   1  1  1 |  0  0\n",
      " 9  +7.318e-02  +5.665e-02  +2e-02  1e-06  3e-05  3e-04  4e-04  0.8015  3e-01   1  1  1 |  0  0\n",
      "10  +7.081e-02  +6.807e-02  +4e-03  2e-07  5e-06  4e-05  6e-05  0.8482  2e-02   1  1  1 |  0  0\n",
      "11  +7.049e-02  +6.975e-02  +1e-03  6e-08  1e-06  1e-05  2e-05  0.9410  2e-01   1  1  1 |  0  0\n",
      "12  +7.041e-02  +7.023e-02  +3e-04  2e-08  3e-07  3e-06  4e-06  0.7730  2e-02   1  1  1 |  0  0\n",
      "13  +7.040e-02  +7.027e-02  +2e-04  1e-08  2e-07  2e-06  3e-06  0.4506  4e-01   1  1  1 |  0  0\n",
      "14  +7.039e-02  +7.035e-02  +5e-05  3e-09  6e-08  5e-07  8e-07  0.7789  4e-02   1  1  1 |  0  0\n",
      "15  +7.038e-02  +7.037e-02  +2e-05  1e-09  3e-08  2e-07  3e-07  0.6730  2e-01   2  1  1 |  0  0\n",
      "16  +7.038e-02  +7.038e-02  +6e-06  4e-10  8e-09  7e-08  1e-07  0.7677  7e-02   2  1  1 |  0  0\n",
      "17  +7.038e-02  +7.038e-02  +1e-06  9e-11  2e-09  2e-08  2e-08  0.8634  1e-01   1  1  1 |  0  0\n",
      "18  +7.038e-02  +7.038e-02  +3e-07  2e-11  4e-10  4e-09  5e-09  0.8095  4e-02   1  1  1 |  0  0\n",
      "19  +7.038e-02  +7.038e-02  +4e-08  2e-12  5e-11  4e-10  6e-10  0.9526  7e-02   2  1  1 |  0  0\n",
      "20  +7.038e-02  +7.038e-02  +5e-09  8e-13  7e-12  6e-11  9e-11  0.8583  1e-02   3  1  1 |  0  0\n",
      "\n",
      "OPTIMAL (within feastol=7.1e-12, reltol=7.6e-08, abstol=5.4e-09).\n",
      "Runtime: 0.000939 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "using LinearAlgebra\n",
    "n = 20;\n",
    "a1 = zeros(n+1,n+1);\n",
    "b1 = [Rd;zeros(n)];\n",
    "c1 = [0;bar_R];\n",
    "d1 = bar_R'*w;\n",
    "a2 = [zeros(n) sqrt(a).*Array{Float64}(I,n,n)];\n",
    "b2 = 1/(2*sqrt(a)).*ones(n);\n",
    "d2 = sqrt(B+n/(4*a));\n",
    "a3 = [zeros(n) sqrt(Sigma)];\n",
    "b3 = sqrt(Sigma)*w;\n",
    "c3 = [1;zeros(n)];\n",
    "@variable(m_socp,x_socp[1:n+1]);\n",
    "@constraint(m_socp,[c1'*x_socp+d1;a1*x_socp+b1] in SecondOrderCone());\n",
    "@constraint(m_socp,[d2;a2*x_socp+b2] in SecondOrderCone());\n",
    "@constraint(m_socp,[c3'*x_socp;a3*x_socp+b3] in SecondOrderCone());\n",
    "@constraint(m_socp,[i=2:n+1],-M <= x_socp[i] <= M);\n",
    "@constraint(m_socp,[i=2:n+1],x_socp[i] >= -w[i-1]);\n",
    "@objective(m_socp, Min, x_socp[1]);\n",
    "optimize!(m_socp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6(c): Plotting the portfolios found\n",
    "\n",
    "Given that you have programmed and executed the optimization problems correctly, the following helper code shall plot the portfolios nicely for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot( names_stocks, portfolio_opt, labels = \"unconstrained portfolio\" )\n",
    "plot!( names_stocks, JuMP.value.(x_mip + w), labels = \"MI-NLP\")\n",
    "plot!( names_stocks, JuMP.value.(x_socp[2:n+1] + w), labels = \"SOCP\")\n",
    "plot!( names_stocks, 3000*bar_R, labels =\"(Scaled) Expected Return\")\n",
    "plot!( names_stocks, 3000*[Sigma[i,i] for i in 1:n], labels =\"(Scaled) Variance\")\n",
    "savefig(\"three.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Evaluating the Solution on Testing Set\n",
    "\n",
    "Again, provided that you have programmed and executed the optimization problems correctly, the following helper code shall compute the Sharpe ratio and other benchmarks for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio = 0.07743046905112376, Return = 0.00436591035529453, Tx Cost = 28, Portfo Value = 11.16058819372345"
     ]
    }
   ],
   "source": [
    "sharpe_IP = sharpe_ratio( path_subgroup, JuMP.value.(x_mip), ones(n), 2 );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio = 0.062327854157761015, Return = 0.0034451790827156716, Tx Cost = 40, Portfo Value = 11.226746195677338"
     ]
    }
   ],
   "source": [
    "sharpe_SOCP = sharpe_ratio( path_subgroup, JuMP.value.(x_socp[2:n+1]), ones(n) , 2 );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio = 0.10687408899641704, Return = 0.010452885714344958, Tx Cost = 40, Portfo Value = 20.000000000000004"
     ]
    }
   ],
   "source": [
    "sharpe_Opt = sharpe_ratio( path_subgroup, portfolio_opt, zeros(n), 2 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II - Competitive Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the compulsory task, we shall implement a projected gradient method (using a constant step size) for the approximated Portfolio optimization problem. \n",
    "\n",
    "We shall consider the full portfolio optimization problem. For this, let us first load the stock data with the following helper code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the full data set!\n",
    "files = glob( \"*_train.csv\", \"./ftec_project_files/\");\n",
    "dfs = DataFrame.( CSV.File.( files ) );\n",
    "T = 800; n = length(dfs);\n",
    "stocks_retur_full = zeros(T,n);\n",
    "for i = 1:n\n",
    "    # compute the realized return R_i(t)\n",
    "    stocks_retur_full[:,i] = (dfs[i].close-dfs[i].open) ./ dfs[i].open;\n",
    "end\n",
    "names_stocks_full = [ dfs[i].Name[1] for i in 1:n ];\n",
    "# calculate r_i and Sigma\n",
    "bar_R_full = [ mean( stocks_retur_full[:,i] ) for i in 1:length(dfs) ];\n",
    "Sigma_full = [ mean( (stocks_retur_full[:,i].-bar_R_full[i]).*(stocks_retur_full[:,j].-bar_R_full[j]) ) for i=1:n, j=1:n ]; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that \"bar_R_full\" is the expected return for all the $n=471$ stocks considered, and \"Sigma_full\" is the $471 \\times 471$ covariance matrix for them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Implementing a Customized Solver for Approximated problem\n",
    "\n",
    "You shall write a few helper functions to compute the objective values, the gradient vector, the projection into the box constraint, etc.. to help you with implementing the customized solver. Some useful syntax are as follows:\n",
    "\n",
    "- For a nonlinear function $h(z)$ (such as the Huber function) on a scalar $z$. Suppose that $x$ is an $n$-dimensional vector, to create the vector \n",
    "\n",
    "$$ [h(x)]_i = h(x_i) $$\n",
    "\n",
    "you may use the syntax\n",
    "\n",
    "$$ \\texttt{h.(x)} $$\n",
    "\n",
    "where the \".\" after \"h\" broadcasts the function to every elements of the vector. \n",
    "- Note that the objective function should be dependent on \"x\", \"w\", \"a\", \"bar_R_full\", \"Sigma_full\", \"upsilon\", \"zeta\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "obj_v (generic function with 1 method)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code/functions here\n",
    "B = 20;\n",
    "Rd = 1.01*sum(bar_R_full);\n",
    "function calc_gamma(delta)\n",
    "    delta = 0.01;\n",
    "    L = a/delta + max(diag(Sigma_full));\n",
    "    gamma = 1/L;\n",
    "    return gamma;\n",
    "end\n",
    "\n",
    "function gd(x,w,a,lambda,upsilon,delta)\n",
    "    @assert length(x)==n;\n",
    "    grad = Sigma_full*x+Sigma_full*w - lambda.*bar_R_full+upsilon.*ones(n);\n",
    "    for i=1:n\n",
    "        if abs(x[i])> delta\n",
    "            grad[i] += sign(x[i])*upsilon*a;\n",
    "        else\n",
    "            grad[i] += upsilon*(a/delta)*x[i];\n",
    "        end\n",
    "    end\n",
    "    return grad;\n",
    "end\n",
    "\n",
    "function obj_v(x,w,a,lambda,upsilon,delta)\n",
    "    @assert length(x)==n;\n",
    "    obj = 1/2*((x+w)'*Sigma_full*(x+w))+lambda*(Rd-bar_R_full'*x-bar_R_full'*w)+(upsilon*sum(x)-upsilon*B);\n",
    "    for i=1:n\n",
    "        if abs(x[i])>delta\n",
    "            obj += upsilon*(a*abs(x[i])-a*delta/2);\n",
    "        else\n",
    "            obj += upsilon*(a/(2*delta)*x[i]^2);\n",
    "        end\n",
    "    end\n",
    "    return obj;\n",
    "end\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may program the iterative algorithm of your choice as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameters as specified by the problem\n",
    "M = 20; w = 1*ones(n); a = 1; upsilon = 10; lambda = 34280; delta = 0.01;\n",
    "\n",
    "# initialize the algorithm\n",
    "x_custom = zeros(n); \n",
    "store_obj = []\n",
    "push!(store_obj, obj_v(x_custom,w,a,lambda,upsilon,delta) ) # replace \"..\" with the function you wrote for computing the objective val.\n",
    "\n",
    "# calculate l and u - your code here (should be a simple formula)\n",
    "u = M.*ones(n);\n",
    "l = -w;\n",
    "\n",
    "for iteration_no = 1 : 50000 # feel free to adjust the number of iterations run here.\n",
    "    # your code here\n",
    "    gamma = 1/(iteration_no+1);\n",
    "    x_custom -= gamma* gd(x_custom,w,a,lambda,upsilon,delta);\n",
    "    for i=1:n\n",
    "        if x_custom[i] > u[i]\n",
    "            x_custom[i] = u[i];\n",
    "        elseif x_custom[i] < l[i]\n",
    "            x_custom[i] = l[i];\n",
    "        end\n",
    "    end\n",
    "    push!(store_obj, obj_v(x_custom,w,a,lambda,upsilon,delta) ) # replace \"..\" with the function you wrote for computing the objective val.\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot( store_obj, title = \"objective value\") # plot the trajectory of the optimization algorithm\n",
    "savefig(\"obj.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the post-processing step as specified in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_custom_pp = copy( x_custom )\n",
    "x_custom_pp[ abs.(x_custom_pp) .< delta ] .= 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code computes the sharpe ratio, return, transaction cost, total cost of portfolio which will be used to calculate your score for the competitive task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio = 0.09294117457434602, Return = 1.3015641214060631, Tx Cost = 424, Portfo Value = 2981.296055217791"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09294117457434602"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sharpe_PPGD = sharpe_ratio( \"./ftec_project_files/\", x_custom_pp, ones(n), 2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may also help to visualize the portfolio with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot( names_stocks_full, x_custom_pp + w, labels = \"gradient descent\" )\n",
    "plot!( names_stocks_full, 1000*bar_R_full, labels =\"(Scaled) Expected Return\")\n",
    "plot!( names_stocks_full, 1000*[Sigma_full[i,i] for i in 1:n], labels =\"(Scaled) Variance\")\n",
    "savefig(\"competitive.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
